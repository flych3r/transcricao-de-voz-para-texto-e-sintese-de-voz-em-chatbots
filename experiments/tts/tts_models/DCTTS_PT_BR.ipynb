{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hrazsFpbNV6"
   },
   "source": [
    "**Cloning repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kn0oD_mOJk8d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esb-3ng_Alsp"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCH93GWAAaZk"
   },
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSXuXnm4a0WA"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Edresson/TTS-Conv.git\n",
    "import os\n",
    "import time\n",
    "os.chdir('TTS-Conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpYNgqrZcJKn"
   },
   "source": [
    "**Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KZA4b_CbMqx"
   },
   "outputs": [],
   "source": [
    "from hyperparams import Hyperparams as hp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from train import Graph\n",
    "from utils import *\n",
    "from scipy.io.wavfile import write\n",
    "from tqdm import tqdm\n",
    "from librosa import  display\n",
    "from data_load import text_normalize,load_vocab\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6Krn8k1inC_"
   },
   "source": [
    "\n",
    "\n",
    "**Download Weights**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiYHf3lKhi9z"
   },
   "outputs": [],
   "source": [
    "!wget -c -q --show-progress -O ./saver-text.zip https://www.dropbox.com/s/oeafuy4yp7nqj5y/saver-text.zip?dl=0\n",
    "!ls\n",
    "!unzip saver-text.zip  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dV6cXXlfi72r"
   },
   "source": [
    "**Restore Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6Kvtq0QilgV"
   },
   "outputs": [],
   "source": [
    "# Load graph\n",
    "g = Graph(mode=\"synthesize\"); print(\"Graph loaded\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore parameters\n",
    "var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'Text2Mel')\n",
    "saver1 = tf.train.Saver(var_list=var_list)\n",
    "saver1.restore(sess, os.path.join('saver-text','text2mel','saver'))\n",
    "print(\"Text2Mel Restored!\")\n",
    "\n",
    "var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SSRN') + tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gs')\n",
    "saver2 = tf.train.Saver(var_list=var_list)\n",
    "saver2.restore(sess, os.path.join('saver-text','mel2linear','saver'))\n",
    "print(\"SSRN Restored!\")\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6CqH4OhkeEk"
   },
   "source": [
    "**Synthesize**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3hRL1SfclS5"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "import textwrap\n",
    "\n",
    "def sysntesise_text(sentence, fp=None):\n",
    "    start = time.time()\n",
    "    # print('input text: ',frase)\n",
    "    wavs = []\n",
    "    for frase in textwrap.wrap(sentence, width=100, break_long_words=False):\n",
    "        frase = '1 '+frase # add factor \n",
    "        #normalize remove inavalid characters\n",
    "        frase = text_normalize(frase.split(\" \", 1)[-1]).strip() + \"E\" # text normalization, E: EOS\n",
    "\n",
    "        # print('normalized text:',frase)\n",
    "            \n",
    "        char2idx, idx2char = load_vocab()\n",
    "            \n",
    "        #convert characters to numbers\n",
    "        text = np.zeros((1, hp.max_N), np.int32) #hp.max_N = 128, is the max number for characters \n",
    "        text[0, :len(frase)] = [char2idx[char] for char in frase]\n",
    "\n",
    "        # print('converted text:',text)\n",
    "\n",
    "        L = text\n",
    "        # Feed Forward\n",
    "        ## mel\n",
    "        # note: hp.max_T can be changed depending on the phrase to be synthesized, the default value is 210, which generates an audio of maximum 10 seconds, if it decreases this value can obtain a greater speed of synthesis.\n",
    "        hp.max_T = 210 \n",
    "        Y = np.zeros((len(L), hp.max_T, hp.n_mels), np.float32)\n",
    "        prev_max_attentions = np.zeros((len(L),), np.int32)\n",
    "        for j in range(hp.max_T):\n",
    "            _gs, _Y, _max_attentions, _alignments = sess.run([g.global_step, g.Y, g.max_attentions, g.alignments], {g.L: L,g.mels: Y, g.prev_max_attentions: prev_max_attentions})\n",
    "            Y[:, j, :] = _Y[:, j, :]\n",
    "            prev_max_attentions = _max_attentions[:, j]\n",
    "\n",
    "        # Get magnitude\n",
    "        Z = sess.run(g.Z, {g.Y: Y})\n",
    "\n",
    "        # Generate wav files\n",
    "        for i, mag in enumerate(Z):\n",
    "            # print(\"Working on file\", i+1)\n",
    "            wav = spectrogram2wav(mag)\n",
    "            f = io.BytesIO()\n",
    "            write(f, hp.sr, wav)\n",
    "            #save for frase.wav\n",
    "            wavs.append(f)\n",
    "\n",
    "    wavs = [AudioSegment.from_file_using_temporary_files(w) for w in wavs]\n",
    "    wav = sum(wavs)\n",
    "    wav = process_audio(wav)\n",
    "    if fp:\n",
    "        wav.export(\"{}.wav\".format(fp), format=\"wav\")\n",
    "        # write(\"{}.wav\".format(fp), hp.sr, wav)\n",
    "    end = time.time()\n",
    "    print(end - start, 'segundos')\n",
    "    with open('times.txt', 'a') as f:\n",
    "        print('{}, {}, {}, {}'.format(fp, end - start, len(sentence), get_audio_length('{}.wav'.format(fp))), file=f)\n",
    "    IPython.display.display(wav)\n",
    "    print('*' * 80)\n",
    "    return wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIIC2mI5FXXg"
   },
   "outputs": [],
   "source": [
    "!unzip sentences.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN2A9DdEki64"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "sentences_dict = dict()\n",
    "for fp in glob.glob('*.txt'):\n",
    "    with open(fp) as f:\n",
    "        sentences = f.readlines()\n",
    "    sentences_dict[fp] = [sent.strip() for sent in sentences][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFjoPJqmkjlQ"
   },
   "outputs": [],
   "source": [
    "import pydub\n",
    "\n",
    "def process_audio(audio):\n",
    "    return sum(pydub.silence.split_on_silence(audio, silence_thresh=-36)).set_sample_width(2).set_channels(1).set_frame_rate(22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LESuvqKJQ4MC"
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import contextlib\n",
    "\n",
    "def get_audio_length(file_path):\n",
    "    if file_path.endswith('.wav'):\n",
    "        with contextlib.closing(wave.open(file_path,'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            return duration\n",
    "    if file_path.endswith('.mp3'):\n",
    "        audio = MP3(file_path)\n",
    "        return audio.info.length\n",
    "    raise Exception('Unsuported file format. File must be wav or mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrp15QdSBckD"
   },
   "outputs": [],
   "source": [
    "# test_sentences =[\n",
    "#         # \"O capital de uma empresa depende de sua produção\",\n",
    "#         # \"Se não fosse ela tudo teria sido melhor, ou talvez não.\",\n",
    "#         # \"A principal personagem no filme é uma gueixa\",\n",
    "#         # \"Espere seu amigo em casa\",\n",
    "#         # \"A juventude tinha que revolucionar a escola\",\n",
    "#         # \"A cantora terá quatro meses para ensaiar seu canto\",\n",
    "# ]\n",
    "\n",
    "# https://cartadeservicos.ce.gov.br/ConsultaCesec/pg_cs_servico.aspx\n",
    "\n",
    "with open('times.txt', 'w') as f:\n",
    "    print('fp, inf_time, sent_length, audio_length', file=f)\n",
    "\n",
    "for n, sentences in sentences_dict.items():\n",
    "    n = n.split('_')[1].split('.')[0].upper()\n",
    "    for i, frase in enumerate(sentences):\n",
    "        if i == 2:\n",
    "            break\n",
    "        print('\\n'.join(textwrap.wrap(frase, width=80)))\n",
    "        sysntesise_text(frase, '{}_{}'.format(n, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPx5z7fEO5lg"
   },
   "outputs": [],
   "source": [
    "from notify import send\n",
    "send('Finished DCTTS run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plEqFJygqeDH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir audios\n",
    "rm audios/*.wav\n",
    "mv *.wav audios\n",
    "zip -r audios_dctts_cpu.zip audios times.txt\n",
    "cp audios_dctts_cpu.zip '/content/drive/My Drive/TCC_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXti8T_-DJtY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DCTTS_PT_BR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
