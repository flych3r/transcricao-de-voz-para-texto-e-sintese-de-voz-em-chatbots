{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uKCN6dIiO2C"
   },
   "source": [
    "# Speech 2 Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpehWds9ibSD"
   },
   "source": [
    "## Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "px-weAfxigYy"
   },
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition  gTTS pydub azure-cognitiveservices-speech google-cloud-speech python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWSkIQWLioR5"
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "import time\n",
    "import wave\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from google.cloud import speech_v1 as speech\n",
    "from google.cloud import storage\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfiK8XTwlolu"
   },
   "outputs": [],
   "source": [
    "data_path = Path('/content/drive/My Drive/TCC_data/')\n",
    "env_path = Path('/content/drive/My Drive/Colab Notebooks') / '.env'\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhbafoNg8TkV"
   },
   "outputs": [],
   "source": [
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "\n",
    "def wrap_print(text):\n",
    "    for element in wrapper.wrap(text=text):\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPgEQWxAzHYL"
   },
   "outputs": [],
   "source": [
    "def get_audio_length(file_path):\n",
    "    fname = str(file_path)\n",
    "\n",
    "    with wave.open(fname,'r') as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "    \n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5mhq2szqOpm"
   },
   "outputs": [],
   "source": [
    "def play_audio_file(file_path):\n",
    "    with open(file_path, 'rb') as riff:\n",
    "        audio = AudioSegment.from_file(riff)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70KWAAHHTmHs"
   },
   "outputs": [],
   "source": [
    "def translate_text_to_audio(text, lang='pt-br'):\n",
    "    tts = gTTS(text, lang=lang)\n",
    "\n",
    "    # Salva o arquivo de audio\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")      \n",
    "    file_path = 'tts-{}.mp3'.format(dt_string)\n",
    "    tts.save(file_path)\n",
    "    print(\"Estou aprendendo o que vocÃª disse...\")\n",
    "\n",
    "    # Da play ao audio\n",
    "    return play_audio_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fJ1FI7AsI5Y"
   },
   "source": [
    "## [Speech Recognizer](https://github.com/Uberi/speech_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc8msfXh6QL1"
   },
   "outputs": [],
   "source": [
    "api_info = {\n",
    "    'api': {\n",
    "        'website': 'https://cloud.google.com/dialogflow',\n",
    "        'pricing': 'https://cloud.google.com/dialogflow/pricing'\n",
    "    }, \n",
    "    'bing': {\n",
    "        'website': 'https://azure.microsoft.com/pt-br/services/cognitive-services/speech-services/',\n",
    "        'pricing': 'https://azure.microsoft.com/pt-br/pricing/details/cognitive-services/speech-services/'\n",
    "    },\n",
    "    'google': {\n",
    "        'website': 'https://developers.google.com/web/updates/2013/01/Voice-Driven-Web-Apps-Introduction-to-the-Web-Speech-API',\n",
    "        'pricing': 'free, very limited quota'\n",
    "    },\n",
    "    'gcloud': {\n",
    "        'website': 'https://cloud.google.com/speech-to-text/',\n",
    "        'pricing': 'https://cloud.google.com/speech-to-text/pricing'\n",
    "    },\n",
    "    'houndify': {\n",
    "        'website': 'https://www.houndify.com/',\n",
    "        'pricing': 'https://www.houndify.com/pricing, apenas ingles?'\n",
    "    },\n",
    "    'ibm': {\n",
    "        'website': 'https://www.ibm.com/br-pt/cloud/watson-speech-to-text',\n",
    "        'pricing':'https://www.ibm.com/br-pt/cloud/watson-speech-to-text/pricing'\n",
    "    },\n",
    "    'sphinx': {\n",
    "        'website': 'https://cmusphinx.github.io/wiki/',\n",
    "        'pricing': 'offline, apenas International French, Mandarin Chinese, Italian'\n",
    "    },\n",
    "    'wit': {\n",
    "        'website': 'https://wit.ai/',\n",
    "        'pricing': 'free, https://wit.ai/docs/http/20200513'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqs135IhklCS"
   },
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "sr_apis = {\n",
    "    # 'api': {\n",
    "    #     'recognize': recognizer.recognize_api,\n",
    "    #     'kwargs': {}\n",
    "    # },\n",
    "    # 'bing': {\n",
    "    #     'recognize': recognizer.recognize_bing,\n",
    "    #     'kwargs': {}\n",
    "    # },\n",
    "    'google': {\n",
    "        'recognize': recognizer.recognize_google,\n",
    "        'kwargs': {\n",
    "            'language': 'pt-br'\n",
    "        }\n",
    "    },\n",
    "    # 'gcloud': {\n",
    "    #     'recognize': recognizer.recognize_google_cloud,\n",
    "    #     'kwargs': {}\n",
    "    # },   \n",
    "    'houndify': {\n",
    "        'recognize': recognizer.recognize_houndify,\n",
    "        'kwargs': {\n",
    "            'client_id': os.getenv('HOUNDIFY_CLIENT_ID'),\n",
    "            'client_key': os.getenv('HOUNDIFY_CLIENT_KEY')\n",
    "        }\n",
    "    },\n",
    "    # 'ibm': {\n",
    "    #     'recognize': recognizer.recognize_ibm,\n",
    "    #     'kwargs': {}\n",
    "    # },\n",
    "    # 'sphinx': {\n",
    "    #     'recognize': recognizer.recognize_sphinx,\n",
    "    #     'kwargs': {}\n",
    "    # },\n",
    "    # 'wit': {\n",
    "    #     'recognize': recognizer.recognize_wit,\n",
    "    #     'kwargs': {}\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5MbPLlWkqCY"
   },
   "source": [
    "### Audio file to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4qlLxi4k9oC"
   },
   "outputs": [],
   "source": [
    "def from_audio_file(file_path, api=None, show_all=False):\n",
    "    audio_file = sr.AudioFile(str(file_path))\n",
    "    with audio_file as source: \n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.record(source)\n",
    "    recognize = sr_apis[api]['recognize']\n",
    "    kwargs = sr_apis[api]['kwargs']\n",
    "    text = recognize(\n",
    "        audio_data=audio, show_all=show_all, **kwargs\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5H7OC0FpaI4"
   },
   "outputs": [],
   "source": [
    "text = from_audio_file(data_path / 'teste.wav', api='google')\n",
    "wrap_print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kdoo85KDrxLv"
   },
   "source": [
    "### Microphone capture to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WRNmcogsCAh"
   },
   "outputs": [],
   "source": [
    "def from_microphone(api=None, show_all=False):\n",
    "\n",
    "    # Habilita o microfone para ouvir o usuario\n",
    "    microphone = sr.Microphone()\n",
    "    with microphone as source:\n",
    "        # Chama a funcao de reducao de ruido disponivel na speech_recognition\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        #A visa ao usuario que esta pronto para ouvir\n",
    "        print(\"Diga alguma coisa: \")\n",
    "        # Armazena a informacao de audio na variavel\n",
    "        audio = microphone.listen(source)\n",
    "        # audio = microfone.listen(source, phrase_time_limit=5)\n",
    "        print(\"gravado\")\n",
    "        # Passa o audio para o reconhecedor de padroes do speech_recognition\n",
    "    recognize = sr_apis[api]['recognize']\n",
    "    kwargs = sr_apis[api]['kwargs']\n",
    "    text = recognize(\n",
    "        audio_data=audio, show_all=show_all, **kwargs\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbeb38vouaWI"
   },
   "outputs": [],
   "source": [
    "# Doesnt work on colab\n",
    "# from_microphone(api='google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_Y6ca5At49G"
   },
   "source": [
    "### Translate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4kfwshzthXS"
   },
   "outputs": [],
   "source": [
    "def translate_audio_to_text(source=None, api=None, **kwargs):\n",
    "    assert api in sr_apis, 'please specify an api'\n",
    "    if source is None:\n",
    "        return from_microphone(api, **kwargs)\n",
    "    return from_audio_file(source, api, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfcolMZpeGLB"
   },
   "source": [
    "## Use APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rK9JOwDqlxha"
   },
   "source": [
    "### Google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KvxIc6Ymezfp"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_google(file_path):\n",
    "    return from_audio_file(file_path, 'google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdYNE1pvlraw"
   },
   "source": [
    "### Wit.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4w0DINvuewva"
   },
   "outputs": [],
   "source": [
    "def split_into_chunks(segment, length=20000/1001, split_on_silence=False, noise_threshold=-36): \n",
    "    chunks = list()\n",
    "    \n",
    "    if split_on_silence is False:\n",
    "        for i in range(0, len(segment), int(length*1000)):\n",
    "            chunks.append(segment[i:i+int(length*1000)])\n",
    "    else:\n",
    "        while len(chunks) < 1:\n",
    "            chunks = pydub.silence.split_on_silence(segment, noise_threshold)\n",
    "            noise_threshold += 4\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if len(chunk) > int(length*1000):\n",
    "            subchunks = split_into_chunks(chunk, length, split_on_silence, noise_threshold+4)\n",
    "            chunks = chunks[:i-1] + subchunks + chunks[i+1:]\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def preprocess_audio(audio):\n",
    "    return audio.set_sample_width(2).set_channels(1).set_frame_rate(8000)\n",
    "\n",
    "def read_audio_into_chunks(file_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    return split_into_chunks(preprocess_audio(audio))\n",
    "\n",
    "def transcribe_audio_wit(file_path):\n",
    "\n",
    "    url = 'https://api.wit.ai/speech'\n",
    "\n",
    "    key = os.getenv('WIT_KEY')\n",
    "\n",
    "    # defining headers for HTTP request\n",
    "    headers = {\n",
    "        'authorization': 'Bearer ' + key,\n",
    "        'content-type': 'audio/raw;encoding=signed-integer;bits=16;rate=8000;endian=little',\n",
    "    }\n",
    "\n",
    "    chunks = read_audio_into_chunks(file_path)\n",
    "\n",
    "    text = []\n",
    "    for audio in chunks:\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            data=io.BufferedReader(io.BytesIO(audio.raw_data))\n",
    "        )\n",
    "\n",
    "        #Get the text\n",
    "        data = json.loads(response.content)\n",
    "        if 'text' in data:\n",
    "            text.append(data['text'])\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0qUkv3VluC1"
   },
   "source": [
    "### Azure Cognitive Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09nw8TxGlz5z"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_azure(file_path):\n",
    "    \"\"\"performs one-shot speech recognition with input from an audio file\"\"\"\n",
    "    \n",
    "    speech_key = os.getenv('AZURE_SPEECH_KEY')\n",
    "    service_region = os.getenv('AZURE_REGION')\n",
    "    \n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=file_path)\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, language=\"pt-BR\", audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    done = False\n",
    "    text = []\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        nonlocal done\n",
    "        done = True\n",
    "    \n",
    "    def recognized_cb(evt):\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            # Do something with the recognized text\n",
    "            text.append(evt.result.text)\n",
    "\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    while not done:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Stop continuous speech recognition\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8MqE54LDNAX"
   },
   "source": [
    "### IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsnvxLsxDPJB"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_watson(file_path):\n",
    "    headers = {\n",
    "        'Content-Type': 'audio/wav',\n",
    "    }\n",
    "\n",
    "    params = (\n",
    "        ('model', 'pt-BR_BroadbandModel'),\n",
    "        ('max_alternatives', 1)\n",
    "    )\n",
    "\n",
    "    key = os.getenv('WATSON_KEY')\n",
    "    url = os.getenv('WATSON_URL')\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    response = requests.post(\n",
    "        url, \n",
    "        headers=headers, \n",
    "        params=params, \n",
    "        data=data, \n",
    "        auth=('apikey', key)\n",
    "    )\n",
    "\n",
    "    data = json.loads(response.content)\n",
    "    \n",
    "    text = []\n",
    "    for alternatives in data['results']:\n",
    "        for alternative in alternatives['alternatives']:\n",
    "            text.append(alternative['transcript'])\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXfrliyy4Dns"
   },
   "source": [
    "### AWS Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLJU1WOg4GE8"
   },
   "outputs": [],
   "source": [
    "def upload_file_to_s3(bucket_name, file_path, file_name, region):\n",
    "    s3_client = boto3.client('s3', region_name=region)\n",
    "    \n",
    "    location = {'LocationConstraint': region}\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        s3_client.upload_fileobj(f, bucket_name, file_name)\n",
    "    \n",
    "\n",
    "def delete_file_from_s3(bucket_name, file_name, region):\n",
    "    s3 = boto3.resource('s3', region_name=region)\n",
    "    obj = s3.Object(bucket_name, file_name)\n",
    "    obj.delete()\n",
    "\n",
    "\n",
    "def transcribe_audio_aws(file_path):\n",
    "    BUCKET_NAME = os.getenv('BUCKET_NAME')\n",
    "    AWS_REGION = os.getenv('AWS_REGION')\n",
    "    AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "    file_name = str(file_path).split('/')[-1]\n",
    "    format = file_name.split('.')[-1]\n",
    "\n",
    "    upload_file_to_s3(BUCKET_NAME, file_path, file_name, AWS_REGION)\n",
    "\n",
    "    job_name = 'speech2text-{}-{}'.format(file_name, time.time())\n",
    "    job_uri = 'https://s3.amazonaws.com/{}/{}'.format(BUCKET_NAME, file_name)\n",
    "\n",
    "    transcribe = boto3.client(\n",
    "        'transcribe', \n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID, \n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n",
    "        region_name=AWS_REGION\n",
    "    )\n",
    "\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=job_name, \n",
    "        Media={'MediaFileUri': job_uri}, \n",
    "        MediaFormat=format, \n",
    "        LanguageCode='pt-BR'\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    text = None\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
    "        response = urlopen(status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "        data = json.loads(response.read())\n",
    "        text = data['results']['transcripts'][0]['transcript']\n",
    "    \n",
    "    delete_file_from_s3(BUCKET_NAME, file_name, AWS_REGION)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYwftD3g6FVy"
   },
   "source": [
    "### Google Cloud Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FQGi3aJ_QQ7"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BS6rA_X6EgA"
   },
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "\n",
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "\n",
    "\n",
    "def transcribe_audio_gcloud(file_path):\n",
    "\n",
    "    GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "    GOOGLE_BUCKET_NAME = os.getenv('GOOGLE_BUCKET_NAME')\n",
    "\n",
    "    file_name = str(file_path).split('/')[-1]\n",
    "\n",
    "    upload_blob(GOOGLE_BUCKET_NAME, file_path, file_name)\n",
    "\n",
    "    storage_uri = \"gs://{}/{}\".format(GOOGLE_BUCKET_NAME, file_name)\n",
    "\n",
    "    client = speech.SpeechClient.from_service_account_json(\n",
    "        GOOGLE_APPLICATION_CREDENTIALS\n",
    "    )\n",
    "    \n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding='LINEAR16',\n",
    "        language_code='pt-BR',\n",
    "        sample_rate_hertz=44100,\n",
    "        audio_channel_count=2,\n",
    "    )\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(uri=storage_uri)\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    op_result = operation.result()\n",
    "    \n",
    "    text = []\n",
    "    for result in op_result.results:\n",
    "        for alternative in result.alternatives:\n",
    "            text.append(alternative.transcript)\n",
    "    \n",
    "    delete_blob(GOOGLE_BUCKET_NAME, file_name)\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "623qMV7wq7ft"
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSugQI8Szomt"
   },
   "outputs": [],
   "source": [
    "wav_files = sorted(glob.glob(str(data_path / '*.wav')))\n",
    "wav_lengths = [get_audio_length(fp) for fp in wav_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeqJp6attTHi"
   },
   "outputs": [],
   "source": [
    "def benchmark():\n",
    "\n",
    "    benchmark_apis = {\n",
    "        'google_web_speech': {\n",
    "            'call': transcribe_audio_google,\n",
    "        },\n",
    "        'wit_speech': {\n",
    "            'call': transcribe_audio_wit,\n",
    "        },\n",
    "        'azure_cognitive_services': {\n",
    "                'call': transcribe_audio_azure,\n",
    "            },\n",
    "        'watson_speech_to_text': {\n",
    "            'call': transcribe_audio_watson,\n",
    "        },\n",
    "        'aws_transcribe': {\n",
    "            'call': transcribe_audio_aws,\n",
    "        },\n",
    "        'gcloud_speech_to_text': {\n",
    "            'call': transcribe_audio_gcloud,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for api in benchmark_apis:\n",
    "        for col in ['file', 'length', 'text', 'time']:\n",
    "            benchmark_apis[api][col] = []\n",
    "\n",
    "    for api in benchmark_apis:\n",
    "\n",
    "        print(api)\n",
    "        start_api = time.time()\n",
    "        api_call = benchmark_apis[api]['call']\n",
    "        \n",
    "        for audio_file, audio_length in zip(wav_files, wav_lengths):\n",
    "            file_name = audio_file.split('/')[-1]\n",
    "            print(file_name)\n",
    "\n",
    "            start_transcribe = time.time()\n",
    "            text = api_call(audio_file)\n",
    "            total_time_transcribe = time.time() - start_transcribe\n",
    "\n",
    "            benchmark_apis[api]['file'].append(file_name)\n",
    "            benchmark_apis[api]['length'].append(audio_length)\n",
    "            benchmark_apis[api]['text'].append(text)\n",
    "            benchmark_apis[api]['time'].append(total_time_transcribe)\n",
    "\n",
    "        total_time_api = time.time() - start_api\n",
    "        print('took {} seconds'.format(total_time_api))\n",
    "        print('#' * 80)\n",
    "    \n",
    "    return benchmark_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DckfyEHGfcTB"
   },
   "outputs": [],
   "source": [
    "results = benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW5lxuT3FNKe"
   },
   "outputs": [],
   "source": [
    "dataframes = dict()\n",
    "\n",
    "for api in results:\n",
    "    dataframes[api] = pd.DataFrame(results[api]).drop(columns='call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJCotKQQih1y"
   },
   "outputs": [],
   "source": [
    "for api, df in dataframes.items():\n",
    "    print('results {} api'.format(api))\n",
    "    display(df)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XMfeJ2NYFzQ"
   },
   "outputs": [],
   "source": [
    "for fp, length in zip(wav_files, wav_lengths):\n",
    "    file_name = fp.split('/')[-1]\n",
    "    print('=' * 80)\n",
    "    print('transcriptions for {} ({:.03f})'.format(file_name, length))\n",
    "    display(play_audio_file(fp))\n",
    "    for api, df in dataframes.items(): \n",
    "        # print('{} results with {}'.format(api))\n",
    "        filter_ = df['file'] == file_name\n",
    "        text = df[filter_]['text'].values[0]\n",
    "        exec = df[filter_]['time'].values[0]\n",
    "        print('-' * 80)\n",
    "        print('{}: {:.03f}s'.format(api, exec))\n",
    "        wrap_print(text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GP-HEuP8INgk"
   },
   "outputs": [],
   "source": [
    "for api, df in dataframes.items():\n",
    "    df.to_csv(data_path / 'stt_tests' / '{}.csv'.format(api), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vzSTwDN8HKr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "speech_to_text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
