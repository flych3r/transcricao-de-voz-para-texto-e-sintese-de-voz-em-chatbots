{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "Z5xjC35Io-8H",
    "outputId": "a28a641d-121b-488b-f2aa-65cc0934d7ba"
   },
   "outputs": [],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "MRLMjoyjpCyj",
    "outputId": "54b4a93a-8ba6-4d9e-fb40-8771dd4355da"
   },
   "outputs": [],
   "source": [
    "!cp -R '/content/drive/My Drive/TCC_data/embeddings/' .\n",
    "\n",
    "!unzip -d 'word2vec' \"embeddings/word2vec_*.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOoOd_rMpMCN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbC_AhTypRAX"
   },
   "outputs": [],
   "source": [
    "word2vec_cbow_s50 = KeyedVectors.load_word2vec_format('word2vec/cbow_s50.txt')\n",
    "emb_vocabulary_cbow = set(word2vec_cbow_s50.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mXn5Zc8plIj"
   },
   "outputs": [],
   "source": [
    "def clean_str(x):\n",
    "    return re.sub('\\W', ' ', x).lower()\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQKO35a-o7FY"
   },
   "outputs": [],
   "source": [
    "corpus = ['cod_def_cons', 'constituicao', 'voxforge', 'mozilla']\n",
    "\n",
    "data = defaultdict(list)\n",
    "\n",
    "for c in corpus:\n",
    "    df = pd.read_csv(\n",
    "        '/content/drive/My Drive/TCC_data/metrics/data/evaluate_metrics_{}.tsv'.format(c), \n",
    "        sep='\\t'\n",
    "    )\n",
    "    \n",
    "    voc_sentence = df['sentence'].apply(lambda x: clean_str(x).split()).values.tolist()\n",
    "    voc_translation = df['translation'].apply(lambda x: clean_str(x).split()).values.tolist()\n",
    "\n",
    "    voc_sentence_counter = Counter()\n",
    "    for word in flatten_list(voc_sentence):\n",
    "        voc_sentence_counter[word] += 1\n",
    "\n",
    "    voc_translation_counter = Counter()\n",
    "    for word in flatten_list(voc_translation):\n",
    "        voc_translation_counter[word] += 1\n",
    "\n",
    "    voc_sent = set(voc_sentence_counter.keys())\n",
    "    voc_trans = set(voc_translation_counter.keys())\n",
    "    voc_df = voc_sent | voc_trans\n",
    "\n",
    "    voc_missing_sentence = voc_sent - emb_vocabulary_cbow\n",
    "    voc_missing_translation = voc_trans - emb_vocabulary_cbow\n",
    "    voc_missing_df = voc_df - emb_vocabulary_cbow\n",
    "\n",
    "    \n",
    "    data['corpus'].append(c)\n",
    "    data['vocabulary size'].append(len(voc_df))\n",
    "    data['vocabulary missing'].append(len(voc_missing_df))\n",
    "    data['sentence vocabulary'].append(len(voc_sent))\n",
    "    data['sentence missing'].append(len(voc_missing_sentence))\n",
    "    data['transcription vocabulary'].append(len(voc_trans))\n",
    "    data['transcription missing'].append(len(voc_missing_translation))\n",
    "    data['sentences - transcription difference'].append(len(voc_sent - voc_trans))\n",
    "    data['transcription - sentences difference'].append(len(voc_trans - voc_sent))\n",
    "    data['audio length'].append(df['length'].mean())\n",
    "    data['sentence length'].append(df['sentence'].str.len().mean())\n",
    "    data['transcription length'].append(df['translation'].str.len().mean())\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_JWBDCCp2O1"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    '/content/drive/My Drive/TCC_data/metrics/plots/corpus_info.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-gWKRMdqdM1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "corpus_info.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
