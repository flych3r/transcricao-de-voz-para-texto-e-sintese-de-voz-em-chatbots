{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1C7ZCRd9FCi"
   },
   "source": [
    "# String Matching Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGECzfIJ8-5x"
   },
   "source": [
    "## Downloads and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7Kui7q9BWaV"
   },
   "outputs": [],
   "source": [
    "!pip install -U nltk gensim jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYNbqlpgz2Cq"
   },
   "outputs": [],
   "source": [
    "!cp -R '/content/drive/My Drive/TCC_data/embeddings/' .\n",
    "\n",
    "!unzip -d 'word2vec' \"embeddings/word2vec_*.zip\"\n",
    "!unzip -d 'wang2vec' \"embeddings/wang2vec_*.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8d7sCFh-deZ"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import wave\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from jiwer import wer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython import display\n",
    "from nltk.translate import bleu_score, meteor_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.matutils import softcossim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGA-eqYk8vwP"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "display.set_matplotlib_formats('svg')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK6f74JcuclU"
   },
   "source": [
    "## Aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzcvGTNDufLk"
   },
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    if not isinstance(d, dict):\n",
    "        return {parent_key: d}\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def flatten_columns(df, columns):\n",
    "    for col in columns:\n",
    "        df[f'{col}_'] = df[f'{col}'].apply(flatten_dict)\n",
    "        keys = set(chain(*df[f'{col}_'].apply(lambda column: column.keys())))\n",
    "        for key in keys:\n",
    "            column_name = f'{col}_{key}'.lower()\n",
    "            df[column_name] = df[f'{col}_'].apply(\n",
    "                lambda cell: cell[key] if key in cell.keys() else np.NaN\n",
    "            )\n",
    "    cols_to_drop = [(f'{col}', f'{col}_') for col in columns]\n",
    "    return df.drop(columns=list(chain(*cols_to_drop)))\n",
    "\n",
    "def clean_str(x):\n",
    "    return re.sub('\\W', ' ', x).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAQE2lz08qPJ"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCDpEsuvAb_u"
   },
   "outputs": [],
   "source": [
    "sent_1 = 'o rato roeu a roupa do rei de atena'\n",
    "sent_2 = 'de roma o rato roeu a roupa do rei'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nj2MnoAwEZ0Y"
   },
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JSARam--KuM"
   },
   "outputs": [],
   "source": [
    "emb_models = {\n",
    "    'wang2vec_cbow_s50': KeyedVectors.load_word2vec_format('wang2vec/cbow_s50.txt'),\n",
    "    'wang2vec_skip_s50': KeyedVectors.load_word2vec_format('wang2vec/skip_s50.txt'),\n",
    "    'word2vec_cbow_s50': KeyedVectors.load_word2vec_format('word2vec/cbow_s50.txt'),\n",
    "    'word2vec_skip_s50': KeyedVectors.load_word2vec_format('word2vec/skip_s50.txt')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRCHwU1l6yKJ"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(reference, hypothesis, model):\n",
    "    reference = reference.split()\n",
    "    hypotesis = hypothesis.split()\n",
    "    documents = [hypotesis, reference]\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "    similarity_matrix = emb_models[model].similarity_matrix(dictionary)\n",
    "\n",
    "    hypotesis = dictionary.doc2bow(hypotesis)\n",
    "    reference = dictionary.doc2bow(reference)\n",
    "\n",
    "    return softcossim(hypotesis, reference, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brvfEQe4LYWq"
   },
   "outputs": [],
   "source": [
    "for model in emb_models:\n",
    "    print(model, cosine_similarity(sent_1, sent_2, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OekbCDSV-lJm"
   },
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCSve1hu-qjy"
   },
   "outputs": [],
   "source": [
    "def bleu(reference, hypothesis):\n",
    "    references = [reference.split()]\n",
    "    hypothesis = hypothesis.split()\n",
    "\n",
    "    if len(references[0]) == 1:\n",
    "        weights=(1.0, 0.0, 0.0, 0.0)\n",
    "    elif len(references[0]) == 2:\n",
    "        weights=(0.5, 0.5, 0.0, 0.0)\n",
    "    elif len(references[0]) == 3:\n",
    "        weights=(0.4, 0.3, 0.3, 0.0)\n",
    "    else:\n",
    "        weights=(0.4, 0.3, 0.2, 0.1)\n",
    "\n",
    "    return bleu_score.sentence_bleu(references, hypothesis, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfcOZAR2LHMr"
   },
   "outputs": [],
   "source": [
    "bleu(sent_1, sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycDUr-VzEkXs"
   },
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwxz4vRqDFkZ"
   },
   "outputs": [],
   "source": [
    "pt_stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "def meteor(reference, hypothesis):\n",
    "    references = [reference]\n",
    "    hypothesis = hypothesis\n",
    "    return meteor_score.meteor_score(references, hypothesis, stemmer=pt_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHlOcmbTK-48"
   },
   "outputs": [],
   "source": [
    "meteor(sent_1, sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYG4OwBxEmsa"
   },
   "source": [
    "### WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uk6E5_pABgzw"
   },
   "outputs": [],
   "source": [
    "def word_error_rate(reference, hypothesis):\n",
    "    return wer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNo652xjK2Mh"
   },
   "outputs": [],
   "source": [
    "word_error_rate(sent_1, sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPdra3mKJUQa"
   },
   "source": [
    "### Jaccard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duyk3wuXEwq6"
   },
   "outputs": [],
   "source": [
    "def jaccard_distance(reference, hypothesis):\n",
    "    reference = set(reference.split())\n",
    "    hypothesis = set(hypothesis.split())\n",
    "    return nltk.jaccard_distance(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-To28DVDKcis"
   },
   "outputs": [],
   "source": [
    "jaccard_distance(sent_1, sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA4TQ8Q5QrEP"
   },
   "source": [
    "### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Pq3BpGtQutQ"
   },
   "outputs": [],
   "source": [
    "def replace_oov(text):\n",
    "    text = text.split()\n",
    "    text = [oov_words[w][0][1] for w in text]\n",
    "    return ' '.join(text)\n",
    "\n",
    "def eval_metrics(reference, hypotesis, oov=False):\n",
    "    ms = dict()\n",
    "    \n",
    "    reference = clean_str(reference)\n",
    "    hypotesis = clean_str(hypotesis)\n",
    "\n",
    "    if oov:\n",
    "        hypotesis = replace_oov(hypotesis)\n",
    "\n",
    "    for model in emb_models:\n",
    "        ms[model] = cosine_similarity(reference, hypotesis, model)\n",
    "    ms['bleu'] = bleu(reference, hypotesis)\n",
    "    ms['meteor'] = meteor(reference, hypotesis)\n",
    "    ms['wer'] = word_error_rate(reference, hypotesis)\n",
    "    ms['jaccard_distance'] = jaccard_distance(reference, hypotesis)\n",
    "\n",
    "    return OrderedDict(sorted(ms.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bA-mQrZRqGvZ"
   },
   "source": [
    "## Evaluating transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cjE2YxL0-Mm"
   },
   "outputs": [],
   "source": [
    "corpus = 'voxforge'\n",
    "file_path = '/content/drive/My Drive/TCC_data/metrics/data/evaluate_metrics_{}.tsv'.format(corpus)\n",
    "transcribed_df = pd.read_csv(\n",
    "    file_path, \n",
    "    sep='\\t'\n",
    ")\n",
    "transcribed_df.dropna(inplace=True)\n",
    "print(transcribed_df.shape)\n",
    "transcribed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXo6U4dXUVi8"
   },
   "outputs": [],
   "source": [
    "transcribed_df['eval'] = transcribed_df[['sentence', 'translation']].progress_apply(\n",
    "    lambda row: eval_metrics(row['sentence'], row['translation']), axis=1\n",
    ")\n",
    "transcribed_df = flatten_columns(transcribed_df, ['eval'])\n",
    "file_path = '/content/drive/My Drive/TCC_data/metrics/data/evaluate_metrics_{}.tsv'.format(corpus)\n",
    "transcribed_df.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq5eEk7gNxa1"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/TCC_data/embeddings/oov_{}.json'.format(corpus)) as f:\n",
    "    oov_words = json.load(f)\n",
    "\n",
    "transcribed_df['eval'] = transcribed_df[['sentence', 'translation']].progress_apply(\n",
    "    lambda row: eval_metrics(row['sentence'], row['translation'], oov=True), axis=1\n",
    ")\n",
    "transcribed_df = flatten_columns(transcribed_df, ['eval'])\n",
    "file_path = '/content/drive/My Drive/TCC_data/metrics/data/evaluate_metrics_{}_oov.tsv'.format(corpus)\n",
    "transcribed_df.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIddBeyoZWLi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stt_oov_evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
